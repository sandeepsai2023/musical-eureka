{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import google\n",
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from yt_dlp import YoutubeDL\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mYoutubeDL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "YoutubeDL class.\n",
      "\n",
      "YoutubeDL objects are the ones responsible of downloading the\n",
      "actual video file and writing it to disk if the user has requested\n",
      "it, among some other tasks. In most cases there should be one per\n",
      "program. As, given a video URL, the downloader doesn't know how to\n",
      "extract all the needed information, task that InfoExtractors do, it\n",
      "has to pass the URL to one of them.\n",
      "\n",
      "For this, YoutubeDL objects have a method that allows\n",
      "InfoExtractors to be registered in a given order. When it is passed\n",
      "a URL, the YoutubeDL object handles it to the first InfoExtractor it\n",
      "finds that reports being able to handle it. The InfoExtractor extracts\n",
      "all the information about the video or videos the URL refers to, and\n",
      "YoutubeDL process the extracted information, possibly using a File\n",
      "Downloader to download the video.\n",
      "\n",
      "YoutubeDL objects accept a lot of parameters. In order not to saturate\n",
      "the object constructor with arguments, it receives a dictionary of\n",
      "options instead. These options are available through the params\n",
      "attribute for the InfoExtractors to use. The YoutubeDL also\n",
      "registers itself as the downloader in charge for the InfoExtractors\n",
      "that are added to it, so this is a \"mutual registration\".\n",
      "\n",
      "Available options:\n",
      "\n",
      "username:          Username for authentication purposes.\n",
      "password:          Password for authentication purposes.\n",
      "videopassword:     Password for accessing a video.\n",
      "ap_mso:            Adobe Pass multiple-system operator identifier.\n",
      "ap_username:       Multiple-system operator account username.\n",
      "ap_password:       Multiple-system operator account password.\n",
      "usenetrc:          Use netrc for authentication instead.\n",
      "netrc_location:    Location of the netrc file. Defaults to ~/.netrc.\n",
      "netrc_cmd:         Use a shell command to get credentials\n",
      "verbose:           Print additional info to stdout.\n",
      "quiet:             Do not print messages to stdout.\n",
      "no_warnings:       Do not print out anything for warnings.\n",
      "forceprint:        A dict with keys WHEN mapped to a list of templates to\n",
      "                   print to stdout. The allowed keys are video or any of the\n",
      "                   items in utils.POSTPROCESS_WHEN.\n",
      "                   For compatibility, a single list is also accepted\n",
      "print_to_file:     A dict with keys WHEN (same as forceprint) mapped to\n",
      "                   a list of tuples with (template, filename)\n",
      "forcejson:         Force printing info_dict as JSON.\n",
      "dump_single_json:  Force printing the info_dict of the whole playlist\n",
      "                   (or video) as a single JSON line.\n",
      "force_write_download_archive: Force writing download archive regardless\n",
      "                   of 'skip_download' or 'simulate'.\n",
      "simulate:          Do not download the video files. If unset (or None),\n",
      "                   simulate only if listsubtitles, listformats or list_thumbnails is used\n",
      "format:            Video format code. see \"FORMAT SELECTION\" for more details.\n",
      "                   You can also pass a function. The function takes 'ctx' as\n",
      "                   argument and returns the formats to download.\n",
      "                   See \"build_format_selector\" for an implementation\n",
      "allow_unplayable_formats:   Allow unplayable formats to be extracted and downloaded.\n",
      "ignore_no_formats_error: Ignore \"No video formats\" error. Usefull for\n",
      "                   extracting metadata even if the video is not actually\n",
      "                   available for download (experimental)\n",
      "format_sort:       A list of fields by which to sort the video formats.\n",
      "                   See \"Sorting Formats\" for more details.\n",
      "format_sort_force: Force the given format_sort. see \"Sorting Formats\"\n",
      "                   for more details.\n",
      "prefer_free_formats: Whether to prefer video formats with free containers\n",
      "                   over non-free ones of same quality.\n",
      "allow_multiple_video_streams:   Allow multiple video streams to be merged\n",
      "                   into a single file\n",
      "allow_multiple_audio_streams:   Allow multiple audio streams to be merged\n",
      "                   into a single file\n",
      "check_formats      Whether to test if the formats are downloadable.\n",
      "                   Can be True (check all), False (check none),\n",
      "                   'selected' (check selected formats),\n",
      "                   or None (check only if requested by extractor)\n",
      "paths:             Dictionary of output paths. The allowed keys are 'home'\n",
      "                   'temp' and the keys of OUTTMPL_TYPES (in utils/_utils.py)\n",
      "outtmpl:           Dictionary of templates for output names. Allowed keys\n",
      "                   are 'default' and the keys of OUTTMPL_TYPES (in utils/_utils.py).\n",
      "                   For compatibility with youtube-dl, a single string can also be used\n",
      "outtmpl_na_placeholder: Placeholder for unavailable meta fields.\n",
      "restrictfilenames: Do not allow \"&\" and spaces in file names\n",
      "trim_file_name:    Limit length of filename (extension excluded)\n",
      "windowsfilenames:  Force the filenames to be windows compatible\n",
      "ignoreerrors:      Do not stop on download/postprocessing errors.\n",
      "                   Can be 'only_download' to ignore only download errors.\n",
      "                   Default is 'only_download' for CLI, but False for API\n",
      "skip_playlist_after_errors: Number of allowed failures until the rest of\n",
      "                   the playlist is skipped\n",
      "allowed_extractors:  List of regexes to match against extractor names that are allowed\n",
      "overwrites:        Overwrite all video and metadata files if True,\n",
      "                   overwrite only non-video files if None\n",
      "                   and don't overwrite any file if False\n",
      "playlist_items:    Specific indices of playlist to download.\n",
      "playlistrandom:    Download playlist items in random order.\n",
      "lazy_playlist:     Process playlist entries as they are received.\n",
      "matchtitle:        Download only matching titles.\n",
      "rejecttitle:       Reject downloads for matching titles.\n",
      "logger:            Log messages to a logging.Logger instance.\n",
      "logtostderr:       Print everything to stderr instead of stdout.\n",
      "consoletitle:      Display progress in console window's titlebar.\n",
      "writedescription:  Write the video description to a .description file\n",
      "writeinfojson:     Write the video description to a .info.json file\n",
      "clean_infojson:    Remove internal metadata from the infojson\n",
      "getcomments:       Extract video comments. This will not be written to disk\n",
      "                   unless writeinfojson is also given\n",
      "writeannotations:  Write the video annotations to a .annotations.xml file\n",
      "writethumbnail:    Write the thumbnail image to a file\n",
      "allow_playlist_files: Whether to write playlists' description, infojson etc\n",
      "                   also to disk when using the 'write*' options\n",
      "write_all_thumbnails:  Write all thumbnail formats to files\n",
      "writelink:         Write an internet shortcut file, depending on the\n",
      "                   current platform (.url/.webloc/.desktop)\n",
      "writeurllink:      Write a Windows internet shortcut file (.url)\n",
      "writewebloclink:   Write a macOS internet shortcut file (.webloc)\n",
      "writedesktoplink:  Write a Linux internet shortcut file (.desktop)\n",
      "writesubtitles:    Write the video subtitles to a file\n",
      "writeautomaticsub: Write the automatically generated subtitles to a file\n",
      "listsubtitles:     Lists all available subtitles for the video\n",
      "subtitlesformat:   The format code for subtitles\n",
      "subtitleslangs:    List of languages of the subtitles to download (can be regex).\n",
      "                   The list may contain \"all\" to refer to all the available\n",
      "                   subtitles. The language can be prefixed with a \"-\" to\n",
      "                   exclude it from the requested languages, e.g. ['all', '-live_chat']\n",
      "keepvideo:         Keep the video file after post-processing\n",
      "daterange:         A utils.DateRange object, download only if the upload_date is in the range.\n",
      "skip_download:     Skip the actual download of the video file\n",
      "cachedir:          Location of the cache files in the filesystem.\n",
      "                   False to disable filesystem cache.\n",
      "noplaylist:        Download single video instead of a playlist if in doubt.\n",
      "age_limit:         An integer representing the user's age in years.\n",
      "                   Unsuitable videos for the given age are skipped.\n",
      "min_views:         An integer representing the minimum view count the video\n",
      "                   must have in order to not be skipped.\n",
      "                   Videos without view count information are always\n",
      "                   downloaded. None for no limit.\n",
      "max_views:         An integer representing the maximum view count.\n",
      "                   Videos that are more popular than that are not\n",
      "                   downloaded.\n",
      "                   Videos without view count information are always\n",
      "                   downloaded. None for no limit.\n",
      "download_archive:  A set, or the name of a file where all downloads are recorded.\n",
      "                   Videos already present in the file are not downloaded again.\n",
      "break_on_existing: Stop the download process after attempting to download a\n",
      "                   file that is in the archive.\n",
      "break_per_url:     Whether break_on_reject and break_on_existing\n",
      "                   should act on each input URL as opposed to for the entire queue\n",
      "cookiefile:        File name or text stream from where cookies should be read and dumped to\n",
      "cookiesfrombrowser:  A tuple containing the name of the browser, the profile\n",
      "                   name/path from where cookies are loaded, the name of the keyring,\n",
      "                   and the container name, e.g. ('chrome', ) or\n",
      "                   ('vivaldi', 'default', 'BASICTEXT') or ('firefox', 'default', None, 'Meta')\n",
      "legacyserverconnect: Explicitly allow HTTPS connection to servers that do not\n",
      "                   support RFC 5746 secure renegotiation\n",
      "nocheckcertificate:  Do not verify SSL certificates\n",
      "client_certificate:  Path to client certificate file in PEM format. May include the private key\n",
      "client_certificate_key:  Path to private key file for client certificate\n",
      "client_certificate_password:  Password for client certificate private key, if encrypted.\n",
      "                    If not provided and the key is encrypted, yt-dlp will ask interactively\n",
      "prefer_insecure:   Use HTTP instead of HTTPS to retrieve information.\n",
      "                   (Only supported by some extractors)\n",
      "enable_file_urls:  Enable file:// URLs. This is disabled by default for security reasons.\n",
      "http_headers:      A dictionary of custom headers to be used for all requests\n",
      "proxy:             URL of the proxy server to use\n",
      "geo_verification_proxy:  URL of the proxy to use for IP address verification\n",
      "                   on geo-restricted sites.\n",
      "socket_timeout:    Time to wait for unresponsive hosts, in seconds\n",
      "bidi_workaround:   Work around buggy terminals without bidirectional text\n",
      "                   support, using fridibi\n",
      "debug_printtraffic:Print out sent and received HTTP traffic\n",
      "default_search:    Prepend this string if an input url is not valid.\n",
      "                   'auto' for elaborate guessing\n",
      "encoding:          Use this encoding instead of the system-specified.\n",
      "extract_flat:      Whether to resolve and process url_results further\n",
      "                   * False:     Always process. Default for API\n",
      "                   * True:      Never process\n",
      "                   * 'in_playlist': Do not process inside playlist/multi_video\n",
      "                   * 'discard': Always process, but don't return the result\n",
      "                                from inside playlist/multi_video\n",
      "                   * 'discard_in_playlist': Same as \"discard\", but only for\n",
      "                                playlists (not multi_video). Default for CLI\n",
      "wait_for_video:    If given, wait for scheduled streams to become available.\n",
      "                   The value should be a tuple containing the range\n",
      "                   (min_secs, max_secs) to wait between retries\n",
      "postprocessors:    A list of dictionaries, each with an entry\n",
      "                   * key:  The name of the postprocessor. See\n",
      "                           yt_dlp/postprocessor/__init__.py for a list.\n",
      "                   * when: When to run the postprocessor. Allowed values are\n",
      "                           the entries of utils.POSTPROCESS_WHEN\n",
      "                           Assumed to be 'post_process' if not given\n",
      "progress_hooks:    A list of functions that get called on download\n",
      "                   progress, with a dictionary with the entries\n",
      "                   * status: One of \"downloading\", \"error\", or \"finished\".\n",
      "                             Check this first and ignore unknown values.\n",
      "                   * info_dict: The extracted info_dict\n",
      "\n",
      "                   If status is one of \"downloading\", or \"finished\", the\n",
      "                   following properties may also be present:\n",
      "                   * filename: The final filename (always present)\n",
      "                   * tmpfilename: The filename we're currently writing to\n",
      "                   * downloaded_bytes: Bytes on disk\n",
      "                   * total_bytes: Size of the whole file, None if unknown\n",
      "                   * total_bytes_estimate: Guess of the eventual file size,\n",
      "                                           None if unavailable.\n",
      "                   * elapsed: The number of seconds since download started.\n",
      "                   * eta: The estimated time in seconds, None if unknown\n",
      "                   * speed: The download speed in bytes/second, None if\n",
      "                            unknown\n",
      "                   * fragment_index: The counter of the currently\n",
      "                                     downloaded video fragment.\n",
      "                   * fragment_count: The number of fragments (= individual\n",
      "                                     files that will be merged)\n",
      "\n",
      "                   Progress hooks are guaranteed to be called at least once\n",
      "                   (with status \"finished\") if the download is successful.\n",
      "postprocessor_hooks:  A list of functions that get called on postprocessing\n",
      "                   progress, with a dictionary with the entries\n",
      "                   * status: One of \"started\", \"processing\", or \"finished\".\n",
      "                             Check this first and ignore unknown values.\n",
      "                   * postprocessor: Name of the postprocessor\n",
      "                   * info_dict: The extracted info_dict\n",
      "\n",
      "                   Progress hooks are guaranteed to be called at least twice\n",
      "                   (with status \"started\" and \"finished\") if the processing is successful.\n",
      "merge_output_format: \"/\" separated list of extensions to use when merging formats.\n",
      "final_ext:         Expected final extension; used to detect when the file was\n",
      "                   already downloaded and converted\n",
      "fixup:             Automatically correct known faults of the file.\n",
      "                   One of:\n",
      "                   - \"never\": do nothing\n",
      "                   - \"warn\": only emit a warning\n",
      "                   - \"detect_or_warn\": check whether we can do anything\n",
      "                                       about it, warn otherwise (default)\n",
      "source_address:    Client-side IP address to bind to.\n",
      "impersonate:       Client to impersonate for requests.\n",
      "                   An ImpersonateTarget (from yt_dlp.networking.impersonate)\n",
      "sleep_interval_requests: Number of seconds to sleep between requests\n",
      "                   during extraction\n",
      "sleep_interval:    Number of seconds to sleep before each download when\n",
      "                   used alone or a lower bound of a range for randomized\n",
      "                   sleep before each download (minimum possible number\n",
      "                   of seconds to sleep) when used along with\n",
      "                   max_sleep_interval.\n",
      "max_sleep_interval:Upper bound of a range for randomized sleep before each\n",
      "                   download (maximum possible number of seconds to sleep).\n",
      "                   Must only be used along with sleep_interval.\n",
      "                   Actual sleep time will be a random float from range\n",
      "                   [sleep_interval; max_sleep_interval].\n",
      "sleep_interval_subtitles: Number of seconds to sleep before each subtitle download\n",
      "listformats:       Print an overview of available video formats and exit.\n",
      "list_thumbnails:   Print a table of all thumbnails and exit.\n",
      "match_filter:      A function that gets called for every video with the signature\n",
      "                   (info_dict, *, incomplete: bool) -> Optional[str]\n",
      "                   For backward compatibility with youtube-dl, the signature\n",
      "                   (info_dict) -> Optional[str] is also allowed.\n",
      "                   - If it returns a message, the video is ignored.\n",
      "                   - If it returns None, the video is downloaded.\n",
      "                   - If it returns utils.NO_DEFAULT, the user is interactively\n",
      "                     asked whether to download the video.\n",
      "                   - Raise utils.DownloadCancelled(msg) to abort remaining\n",
      "                     downloads when a video is rejected.\n",
      "                   match_filter_func in utils/_utils.py is one example for this.\n",
      "color:             A Dictionary with output stream names as keys\n",
      "                   and their respective color policy as values.\n",
      "                   Can also just be a single color policy,\n",
      "                   in which case it applies to all outputs.\n",
      "                   Valid stream names are 'stdout' and 'stderr'.\n",
      "                   Valid color policies are one of 'always', 'auto',\n",
      "                   'no_color', 'never', 'auto-tty' or 'no_color-tty'.\n",
      "geo_bypass:        Bypass geographic restriction via faking X-Forwarded-For\n",
      "                   HTTP header\n",
      "geo_bypass_country:\n",
      "                   Two-letter ISO 3166-2 country code that will be used for\n",
      "                   explicit geographic restriction bypassing via faking\n",
      "                   X-Forwarded-For HTTP header\n",
      "geo_bypass_ip_block:\n",
      "                   IP range in CIDR notation that will be used similarly to\n",
      "                   geo_bypass_country\n",
      "external_downloader: A dictionary of protocol keys and the executable of the\n",
      "                   external downloader to use for it. The allowed protocols\n",
      "                   are default|http|ftp|m3u8|dash|rtsp|rtmp|mms.\n",
      "                   Set the value to 'native' to use the native downloader\n",
      "compat_opts:       Compatibility options. See \"Differences in default behavior\".\n",
      "                   The following options do not work when used through the API:\n",
      "                   filename, abort-on-error, multistreams, no-live-chat,\n",
      "                   format-sort, no-clean-infojson, no-playlist-metafiles,\n",
      "                   no-keep-subs, no-attach-info-json, allow-unsafe-ext.\n",
      "                   Refer __init__.py for their implementation\n",
      "progress_template: Dictionary of templates for progress outputs.\n",
      "                   Allowed keys are 'download', 'postprocess',\n",
      "                   'download-title' (console title) and 'postprocess-title'.\n",
      "                   The template is mapped on a dictionary with keys 'progress' and 'info'\n",
      "retry_sleep_functions: Dictionary of functions that takes the number of attempts\n",
      "                   as argument and returns the time to sleep in seconds.\n",
      "                   Allowed keys are 'http', 'fragment', 'file_access'\n",
      "download_ranges:   A callback function that gets called for every video with\n",
      "                   the signature (info_dict, ydl) -> Iterable[Section].\n",
      "                   Only the returned sections will be downloaded.\n",
      "                   Each Section is a dict with the following keys:\n",
      "                   * start_time: Start time of the section in seconds\n",
      "                   * end_time: End time of the section in seconds\n",
      "                   * title: Section title (Optional)\n",
      "                   * index: Section number (Optional)\n",
      "force_keyframes_at_cuts: Re-encode the video when downloading ranges to get precise cuts\n",
      "noprogress:        Do not print the progress bar\n",
      "live_from_start:   Whether to download livestreams videos from the start\n",
      "\n",
      "The following parameters are not used by YoutubeDL itself, they are used by\n",
      "the downloader (see yt_dlp/downloader/common.py):\n",
      "nopart, updatetime, buffersize, ratelimit, throttledratelimit, min_filesize,\n",
      "max_filesize, test, noresizebuffer, retries, file_access_retries, fragment_retries,\n",
      "continuedl, xattr_set_filesize, hls_use_mpegts, http_chunk_size,\n",
      "external_downloader_args, concurrent_fragment_downloads, progress_delta.\n",
      "\n",
      "The following options are used by the post processors:\n",
      "ffmpeg_location:   Location of the ffmpeg/avconv binary; either the path\n",
      "                   to the binary or its containing directory.\n",
      "postprocessor_args: A dictionary of postprocessor/executable keys (in lower case)\n",
      "                   and a list of additional command-line arguments for the\n",
      "                   postprocessor/executable. The dict can also have \"PP+EXE\" keys\n",
      "                   which are used when the given exe is used by the given PP.\n",
      "                   Use 'default' as the name for arguments to passed to all PP\n",
      "                   For compatibility with youtube-dl, a single list of args\n",
      "                   can also be used\n",
      "\n",
      "The following options are used by the extractors:\n",
      "extractor_retries: Number of times to retry for known errors (default: 3)\n",
      "dynamic_mpd:       Whether to process dynamic DASH manifests (default: True)\n",
      "hls_split_discontinuity: Split HLS playlists to different formats at\n",
      "                   discontinuities such as ad breaks (default: False)\n",
      "extractor_args:    A dictionary of arguments to be passed to the extractors.\n",
      "                   See \"EXTRACTOR ARGUMENTS\" for details.\n",
      "                   E.g. {'youtube': {'skip': ['dash', 'hls']}}\n",
      "mark_watched:      Mark videos watched (even with --simulate). Only for YouTube\n",
      "\n",
      "The following options are deprecated and may be removed in the future:\n",
      "\n",
      "break_on_reject:   Stop the download process when encountering a video that\n",
      "                   has been filtered out.\n",
      "                   - `raise DownloadCancelled(msg)` in match_filter instead\n",
      "force_generic_extractor: Force downloader to use the generic extractor\n",
      "                   - Use allowed_extractors = ['generic', 'default']\n",
      "playliststart:     - Use playlist_items\n",
      "                   Playlist item to start at.\n",
      "playlistend:       - Use playlist_items\n",
      "                   Playlist item to end at.\n",
      "playlistreverse:   - Use playlist_items\n",
      "                   Download playlist items in reverse order.\n",
      "forceurl:          - Use forceprint\n",
      "                   Force printing final URL.\n",
      "forcetitle:        - Use forceprint\n",
      "                   Force printing title.\n",
      "forceid:           - Use forceprint\n",
      "                   Force printing ID.\n",
      "forcethumbnail:    - Use forceprint\n",
      "                   Force printing thumbnail URL.\n",
      "forcedescription:  - Use forceprint\n",
      "                   Force printing description.\n",
      "forcefilename:     - Use forceprint\n",
      "                   Force printing final filename.\n",
      "forceduration:     - Use forceprint\n",
      "                   Force printing duration.\n",
      "allsubtitles:      - Use subtitleslangs = ['all']\n",
      "                   Downloads all the subtitles of the video\n",
      "                   (requires writesubtitles or writeautomaticsub)\n",
      "include_ads:       - Doesn't work\n",
      "                   Download ads as well\n",
      "call_home:         - Not implemented\n",
      "                   Boolean, true iff we are allowed to contact the\n",
      "                   yt-dlp servers for debugging.\n",
      "post_hooks:        - Register a custom postprocessor\n",
      "                   A list of functions that get called as the final step\n",
      "                   for each video file, after all postprocessors have been\n",
      "                   called. The filename will be passed as the only argument.\n",
      "hls_prefer_native: - Use external_downloader = {'m3u8': 'native'} or {'m3u8': 'ffmpeg'}.\n",
      "                   Use the native HLS downloader instead of ffmpeg/avconv\n",
      "                   if True, otherwise use ffmpeg/avconv if False, otherwise\n",
      "                   use downloader suggested by extractor if None.\n",
      "prefer_ffmpeg:     - avconv support is deprecated\n",
      "                   If False, use avconv instead of ffmpeg if both are available,\n",
      "                   otherwise prefer ffmpeg.\n",
      "youtube_include_dash_manifest: - Use extractor_args\n",
      "                   If True (default), DASH manifests and related\n",
      "                   data will be downloaded and processed by extractor.\n",
      "                   You can reduce network I/O by disabling it if you don't\n",
      "                   care about DASH. (only for youtube)\n",
      "youtube_include_hls_manifest: - Use extractor_args\n",
      "                   If True (default), HLS manifests and related\n",
      "                   data will be downloaded and processed by extractor.\n",
      "                   You can reduce network I/O by disabling it if you don't\n",
      "                   care about HLS. (only for youtube)\n",
      "no_color:          Same as `color='no_color'`\n",
      "no_overwrites:     Same as `overwrites=False`\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "Create a FileDownloader object with the given options.\n",
      "@param auto_init    Whether to load the default extractors and print header (if verbose).\n",
      "                    Set to 'no_verbose_header' to not print the header\n",
      "\u001b[0;31mFile:\u001b[0m           ~/GitRepo/musical-eureka/YoutubeDataAnalysis/YoutubeDataAnalysis_venv/lib/python3.12/site-packages/yt_dlp/YoutubeDL.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "YoutubeDL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_watch_history(html_file):\n",
    "    if not os.path.exists(html_file):\n",
    "        raise FileNotFoundError(f\"Cannot find {html_file}\")\n",
    "\n",
    "    with open(html_file, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'lxml')\n",
    "\n",
    "    # Find all watch history entries\n",
    "    entries = soup.find_all('div', class_='content-cell mdl-cell mdl-cell--6-col mdl-typography--body-1')\n",
    "\n",
    "    data = []\n",
    "    for entry in entries:\n",
    "        # Extract the link and title\n",
    "        link = div.find('a', href=re.compile(r'https://www.youtube.com/watch\\?v=.+'))\n",
    "        if link:\n",
    "            meta = get_metadata(link['href'])\n",
    "\n",
    "\n",
    "        # Extract the timestamp\n",
    "        timestamp_tag = entry.find('span')\n",
    "        if timestamp_tag:\n",
    "            timestamp_str = timestamp_tag.get_text(strip=True)\n",
    "            # Parse the timestamp string to a datetime object\n",
    "            try:\n",
    "                # Example format: 'Mon, 01 Jan 2023 12:34:56 GMT'\n",
    "                timestamp = datetime.strptime(timestamp_str, '%a, %d %b %Y %H:%M:%S GMT')\n",
    "            except ValueError:\n",
    "                timestamp = None\n",
    "        else:\n",
    "            timestamp = None\n",
    "\n",
    "        # Extract video ID from URL\n",
    "        # video_id = extract_video_id(url) if url else None\n",
    "\n",
    "        data.append({\n",
    "            'title': title,\n",
    "            'url': url,\n",
    "            # 'video_id': video_id,\n",
    "            'time': timestamp\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    # Drop entries without video_id or timestamp\n",
    "    # df = df.dropna(subset=['video_id', 'time']).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your watch-history.html file\n",
    "WATCH_HISTORY_FILE = '/Users/saisandeep/GitRepo/musical-eureka/YoutubeDataAnalysis/Takeout/YouTube and YouTube Music/history/watch-history.html'\n",
    "temp=parse_watch_history(WATCH_HISTORY_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://music.youtube.com/watch?v=JKlYOUfviXM</td>\n",
       "      <td>https://music.youtube.com/watch?v=JKlYOUfviXM</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://music.youtube.com/watch?v=K1FlAphL2p8</td>\n",
       "      <td>https://music.youtube.com/watch?v=K1FlAphL2p8</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://music.youtube.com/watch?v=u3iR6FP2RpU</td>\n",
       "      <td>https://music.youtube.com/watch?v=u3iR6FP2RpU</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://music.youtube.com/watch?v=W5LIWrArBuA</td>\n",
       "      <td>https://music.youtube.com/watch?v=W5LIWrArBuA</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://music.youtube.com/watch?v=H3Kzh6RrnMc</td>\n",
       "      <td>https://music.youtube.com/watch?v=H3Kzh6RrnMc</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50695</th>\n",
       "      <td>STRANGE LIGHTS Caught on CAMERA üò± | Wholesome ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=F5o2H3hNERA</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50696</th>\n",
       "      <td>Her dog put his paw prints in the concrete at ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=N4SM5tLDv3Q</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50697</th>\n",
       "      <td>‚úÖ Best and ‚ùå Worst way to take a Nap üò¥ #nap #s...</td>\n",
       "      <td>https://www.youtube.com/watch?v=ydVy6-zNVkY</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50698</th>\n",
       "      <td>What are the two stages of memory formation?</td>\n",
       "      <td>https://www.youtube.com/watch?v=f-podo-f8Ak</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50699</th>\n",
       "      <td>Power Nap is a Real Power for Students #shorts</td>\n",
       "      <td>https://www.youtube.com/watch?v=-PhgjR1ST14</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50700 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0          https://music.youtube.com/watch?v=JKlYOUfviXM   \n",
       "1          https://music.youtube.com/watch?v=K1FlAphL2p8   \n",
       "2          https://music.youtube.com/watch?v=u3iR6FP2RpU   \n",
       "3          https://music.youtube.com/watch?v=W5LIWrArBuA   \n",
       "4          https://music.youtube.com/watch?v=H3Kzh6RrnMc   \n",
       "...                                                  ...   \n",
       "50695  STRANGE LIGHTS Caught on CAMERA üò± | Wholesome ...   \n",
       "50696  Her dog put his paw prints in the concrete at ...   \n",
       "50697  ‚úÖ Best and ‚ùå Worst way to take a Nap üò¥ #nap #s...   \n",
       "50698       What are the two stages of memory formation?   \n",
       "50699     Power Nap is a Real Power for Students #shorts   \n",
       "\n",
       "                                                 url  time  \n",
       "0      https://music.youtube.com/watch?v=JKlYOUfviXM  None  \n",
       "1      https://music.youtube.com/watch?v=K1FlAphL2p8  None  \n",
       "2      https://music.youtube.com/watch?v=u3iR6FP2RpU  None  \n",
       "3      https://music.youtube.com/watch?v=W5LIWrArBuA  None  \n",
       "4      https://music.youtube.com/watch?v=H3Kzh6RrnMc  None  \n",
       "...                                              ...   ...  \n",
       "50695    https://www.youtube.com/watch?v=F5o2H3hNERA  None  \n",
       "50696    https://www.youtube.com/watch?v=N4SM5tLDv3Q  None  \n",
       "50697    https://www.youtube.com/watch?v=ydVy6-zNVkY  None  \n",
       "50698    https://www.youtube.com/watch?v=f-podo-f8Ak  None  \n",
       "50699    https://www.youtube.com/watch?v=-PhgjR1ST14  None  \n",
       "\n",
       "[50700 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_file = WATCH_HISTORY_FILE\n",
    "if not os.path.exists(html_file):\n",
    "    raise FileNotFoundError(f\"Cannot find {html_file}\")\n",
    "\n",
    "with open(html_file, 'r', encoding='utf-8') as file:\n",
    "    soup = BeautifulSoup(file, 'lxml')\n",
    "\n",
    "# Find all watch history entries\n",
    "entries = soup.find_all('div', class_='content-cell mdl-cell mdl-cell--6-col mdl-typography--body-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = soup.find_all('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "j =0\n",
    "for i in entries:\n",
    "    print(i)\n",
    "    if j>=20:\n",
    "        break\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUnable to determine the last processed index. Resuming from the beginning.\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=Rq7QIvZCLpg\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=vUYp74USacI\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=KJ-bfcCLNZU\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=T_ihqlYWEhk\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=wgVNUAm5WOc\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=lA1JrYe7JY8\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=boiOYZADJIk\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=4rAkT5meaFY\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=Xiyx3e24csA\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=frNPBOfJOqI\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=lPrjP4A_X4s\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=Tl8sKU7w_g8\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=gbSRMwqPBuI\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=2X7wem572ws\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=Zmty7AC5z5Y\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=ArcI4A5nvBo\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=oF2LhsSdl2c\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=4gLWejOLFbQ\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=K0jNGVPAUWY\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=BvsvsGZtXd0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=fFVQ7GHKp_o\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=MABQ3SbqOI0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=U-wASKNdKog\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=CTHg3Ek3Woc\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=OvMh4FALk5k\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=4LiCS3KKx4g\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=EHKuoZJR6kw\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=NNcBKkKS58Y\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=Urc22NTg-AE\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=MQXb2-D9wzM\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=hEFDhxJdYtE\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=LWvEgJuZUMM\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=w49An0UXmx8\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=hh_BQT4sONM\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=RstpyoOlVEA\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=JSSJkRoD4Rc\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=QPad3uNWgn0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=IfCtDzNTosc\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=wsEgFDAraPI\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=nHFvLI397F8\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=PITp41hifWE\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=l20auRgzPTw\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=FMnVvWnIFGs\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] FMnVvWnIFGs: Private video. Sign in if you've been granted access to this video\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mFailed to get metadata for https://www.youtube.com/watch?v=FMnVvWnIFGs\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=L-TjcdTdpZE\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] L-TjcdTdpZE: Video unavailable. This video is no longer available due to a copyright claim by Dreamworks Animation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mFailed to get metadata for https://www.youtube.com/watch?v=L-TjcdTdpZE\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=wVGig5cwt2g\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=xAzidSLeOws\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=1jmcUhrKfCI\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=4oRrE4c3DNU\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=oawM51GHZFQ\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=RhoZYOI_OuE\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=C4Vk-xEAi5s\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=TWSI9uWPTcM\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=jRw6I-bpoK0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=7cQ_db86UNA\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=g66eNnZyj6k\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=4mq9fN1Lg0A\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=oTEROXKwGGI\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=UD1QJzDp3kQ\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=bX_E03ZI42Q\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=2C5xZzMcp9Q\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=4b2lxjBPwjo\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=TZ5kcknqyac\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=0Mx0WwQnUsI\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=1v2jgs2wo-4\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=oe2n1fr6mFA\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=zvR7R7Je0Rc\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=6hVPMaz2xdc\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=EZubPhvQRew\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=_-bpxBG7AU0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=xqe75p_zmxk\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=M1l-nVYLPdI\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=BZCMX1FqAKg\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=EanaTcUmDKE\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=NfznDOCshxE\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=KpI8D98sRqQ\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=4YNuyoYS07U\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=KDh7QbJ3428\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=EjlBLj-_K9I\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=Tf3UQMnIJVA\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=FsLDWqU_27A\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=_NS9eNHzC4I\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=egZcIJvyK3E\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=dD-PvUmvA1A\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=eIaQWd_xLZs\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=avxunGzXCs4\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=hhy2c_3W-KI\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] hhy2c_3W-KI: Video unavailable. This video is no longer available due to a copyright claim by Storyful Managed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mFailed to get metadata for https://www.youtube.com/watch?v=hhy2c_3W-KI\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=6_Y74xuaplY\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=3VJvK2TSkwc\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=2UuElFsfnvk\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=s3Kjpvp_APo\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=sSdsZgS8kKE\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=wV0XQEqilts\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=FeSatb2Gong\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=ll5leGSzGw0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=mXJlnwoJg3o\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=u7Za1haeVJ0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=WSu0PuHpr-I\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=-BiX9RcdiqU\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=oHBv6iYUx-s\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=lbfqmyn6TFM\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=XtQYZnuf-2E\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=xsf8H9WW-74\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=OvF_21OveMI\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=7OIF1erdmIo\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=dM3oSPqcgzY\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=hNt-TWsKWOM\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=cGTliemsa0w\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=7janKw0pcDY\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=I1mdlk3F8PY\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=LZS92rqGmSo\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=-RKgOIhu4Gc\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=5q2aCds_fJA\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=jmsjKs6H768\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=wT_l2aJBpHE\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=HFegUKLDSic\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=t_3uCh2OSnA\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=s1o_vsAp7tI\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=J2OQFDRDvfw\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=dcmKDbCV9I0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=lLdRJSoGdH8\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=10htHOVSq44\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=NeNd48x1BXM\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=EuCAFW31wNs\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=I2ekcAClP6I\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=5K5KtIx6kO0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=A1RL29YDiSs\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=L2UX0u5Op1A\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=KEp9-TA74qM\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=qaaqKZUwhS0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=-GAE--Zduv8\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=g85JDebtNsI\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=SNooaU2DrxE\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=mlOqs-GW2AY\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=gySlO_eWVko\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=lM0j_iW3Tqc\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=1X5B9l-dVvE\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=1AdTXYSjTto\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] 1AdTXYSjTto: Video unavailable. This video is no longer available due to a copyright claim by Indian Premier League\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mFailed to get metadata for https://www.youtube.com/watch?v=1AdTXYSjTto\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=V-m7zEkRRPY\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=OlnP2UEAmn4\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=xN_MTnUOFG0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=YUHoUXmY2E8\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=7rUgKzBOZ8k\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=louS1YzckqA\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=W7Awv5r3xeg\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=8c6ZYiwiPl0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=gA3TjGIVSZ4\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=D2fC_Nrsvu8\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=PR6cmnfuEnU\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=JGl5DbVwSfY\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=9I5hAefAVSA\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=C9Us_MMt1_w\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=_Q3cmxsAGMY\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=mUf4FXxj-Os\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=Zguu-aC7MZ4\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=6D_lPatg87g\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=GL7yA_jW39A\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=Uc52e0oYWe0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=aR7a__WG3v8\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=-0R_lwlEB6g\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=1sdxm_roMl0\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=z-zqn3qXqc8\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] z-zqn3qXqc8: Video unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mFailed to get metadata for https://www.youtube.com/watch?v=z-zqn3qXqc8\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=7y81KUQBwr4\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=T0kWcDKggqw\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=Khd6xbYp0KQ\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=Z2eWbMgVlgQ\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=-u03ogbdzfw\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=7j5jSmNJ73U\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=Xo_Rjv_wQLU\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=8-a70-w23FY\u001b[0m\n",
      "\u001b[32mParsing: https://www.youtube.com/watch?v=ErOtgWIBGEw\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data 'Watched https://www.youtube.com/watch?v=ErOtg' does not match format '%b %d %Y %I:%M:%S %p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 121\u001b[0m\n\u001b[1;32m    116\u001b[0m     parse_html(input_file, output_file, resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# main(sys.argv[1], sys.argv[2])\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 116\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(input_file, output_file)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(input_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/saisandeep/GitRepo/musical-eureka/YoutubeDataAnalysis/Takeout/YouTube and YouTube Music/history/tidy-watch-history.html\u001b[39m\u001b[38;5;124m'\u001b[39m, output_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/saisandeep/GitRepo/musical-eureka/YoutubeDataAnalysis/Takeout/YouTube and YouTube Music/history/temp.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 116\u001b[0m     \u001b[43mparse_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 66\u001b[0m, in \u001b[0;36mparse_html\u001b[0;34m(input_file, output_file, resume)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timestamp_text:\n\u001b[0;32m---> 66\u001b[0m     dt_obj \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestamp_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mb \u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mI:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     timestamp \u001b[38;5;241m=\u001b[39m dt_obj\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Get the album, artist, and track details\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/_strptime.py:554\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    552\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 554\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    556\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/_strptime.py:333\u001b[0m, in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    331\u001b[0m found \u001b[38;5;241m=\u001b[39m format_regex\u001b[38;5;241m.\u001b[39mmatch(data_string)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    334\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    337\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n",
      "\u001b[0;31mValueError\u001b[0m: time data 'Watched https://www.youtube.com/watch?v=ErOtg' does not match format '%b %d %Y %I:%M:%S %p'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from yt_dlp import YoutubeDL\n",
    "from datetime import datetime\n",
    "from colorama import Fore, Style\n",
    "\n",
    "def get_metadata(url):\n",
    "    ydl_opts = {\n",
    "        'quiet': True,\n",
    "        'no_warnings': True,\n",
    "        'skip_download': True,\n",
    "        'forceurl': True,\n",
    "        'forcetitle': True,\n",
    "        'forcedescription': True,\n",
    "        'writeinfojson': True,\n",
    "        'simulate': True,\n",
    "        'youtube_include_dash_manifest': False\n",
    "    }\n",
    "\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        try:\n",
    "            meta = ydl.extract_info(url, download=False)\n",
    "            return meta\n",
    "        except Exception:\n",
    "            print(f\"{Fore.RED}Failed to get metadata for {url}{Style.RESET_ALL}\")\n",
    "            return None\n",
    "\n",
    "def parse_html(input_file, output_file, resume=False):\n",
    "    with open(input_file, \"r\", encoding = \"utf-8\") as f:\n",
    "        contents = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(contents, 'lxml')\n",
    "    divs = soup.find_all('div', {'class': 'content-cell mdl-cell mdl-cell--6-col mdl-typography--body-1'})\n",
    "\n",
    "    if resume:\n",
    "        last_processed_index = get_last_processed_index(output_file)\n",
    "        if last_processed_index is None:\n",
    "            print(f\"{Fore.YELLOW}Unable to determine the last processed index. Resuming from the beginning.{Style.RESET_ALL}\")\n",
    "            last_processed_index = 0\n",
    "        else:\n",
    "            last_processed_index += 1\n",
    "        divs = divs[last_processed_index:]\n",
    "\n",
    "    # Open CSV writer in append mode\n",
    "    with open(output_file, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        try:\n",
    "            for index, div in enumerate(divs, last_processed_index):\n",
    "                link = div.find('a', href=re.compile(r'https://www.youtube.com/watch\\?v=.+'))\n",
    "                if link:\n",
    "                    print(f\"{Fore.GREEN}Parsing: {link['href']}{Style.RESET_ALL}\")\n",
    "                    meta = get_metadata(link['href'])\n",
    "\n",
    "                    text_list = div.text.split('\\n')\n",
    "                    timestamp_text = None\n",
    "                    for text in text_list:\n",
    "                        if \"WIB\" in text:\n",
    "                            timestamp_text = text.split(\"WIB\")[0].strip().replace(',', '').replace('\\xa0', ' ')\n",
    "                            break\n",
    "\n",
    "                    if timestamp_text:\n",
    "                        try:\n",
    "                            dt_obj = datetime.strptime(timestamp_text, '%b %d %Y %I:%M:%S %p')\n",
    "                            timestamp = dt_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                        except Exception as e:\n",
    "                            timestamp = ''\n",
    "                            print(link,e)\n",
    "                            continue\n",
    "\n",
    "                        # Get the album, artist, and track details\n",
    "                        artist = \"\"\n",
    "                        track = \"\"\n",
    "                        album = \"\"\n",
    "                        duration = \"\"\n",
    "                        if meta:\n",
    "                            if 'artist' in meta:\n",
    "                                artist = meta['artist']\n",
    "                            if 'track' in meta:\n",
    "                                track = meta['track']\n",
    "                            if 'album' in meta:\n",
    "                                album = meta['album']\n",
    "                            if 'duration' in meta:\n",
    "                                duration = str(meta['duration'])\n",
    "\n",
    "                        # Skip the div if artist or track is empty\n",
    "                        if not artist or not track:\n",
    "                            print(f\"{Fore.YELLOW}Skipping empty artist or track{Style.RESET_ALL}\")\n",
    "                            continue\n",
    "\n",
    "                        row = [artist, track, album, timestamp, artist, duration]\n",
    "                        writer.writerow(row)\n",
    "                        print(row)\n",
    "\n",
    "                # Save the index of the last processed div\n",
    "                save_last_processed_index(output_file, index)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"{Fore.RED}Parsing interrupted by user.{Style.RESET_ALL}\")\n",
    "\n",
    "    print(f\"{Fore.GREEN}Parsing complete.{Style.RESET_ALL}\")\n",
    "\n",
    "def get_last_processed_index(output_file):\n",
    "    progress_file = f\"{output_file}.progress\"\n",
    "    if os.path.exists(progress_file):\n",
    "        with open(progress_file, 'r') as file:\n",
    "            last_index = file.read()\n",
    "            if last_index.isdigit():\n",
    "                return int(last_index)\n",
    "    return None\n",
    "\n",
    "def save_last_processed_index(output_file, index):\n",
    "    progress_file = f\"{output_file}.progress\"\n",
    "    with open(progress_file, 'w') as file:\n",
    "        file.write(str(index))\n",
    "\n",
    "def main(input_file='/Users/saisandeep/GitRepo/musical-eureka/YoutubeDataAnalysis/Takeout/YouTube and YouTube Music/history/tidy-watch-history.html', output_file='/Users/saisandeep/GitRepo/musical-eureka/YoutubeDataAnalysis/Takeout/YouTube and YouTube Music/history/temp.csv'):\n",
    "    parse_html(input_file, output_file, resume=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # main(sys.argv[1], sys.argv[2])\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YoutubeDataAnalysis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
